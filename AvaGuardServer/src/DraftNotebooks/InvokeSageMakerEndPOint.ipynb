{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import boto3\n",
    "#import sagemaker\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T06:44:15.123327Z",
     "start_time": "2024-08-05T06:44:15.119859Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.34.153\n"
     ]
    }
   ],
   "source": [
    "print(boto3.__version__)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T06:44:15.594760Z",
     "start_time": "2024-08-05T06:44:15.590697Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "#client = boto3.client('sagemaker-runtime')\n",
    "AWS_ACCESS_KEY = ''\n",
    "AWS_SECRET_KEY = ''\n",
    "AWS_SESSION_TOKEN = \"\"\n",
    "AWS_REGION_NAME = ''\n",
    "# AWS_S3_BUCKET_NAME = \"s3-avalanche-guard\"\n",
    "AWS_S3_BUCKET_NAME = \"avlancheguard-uploaded-images\"\n",
    "\n",
    "client = boto3.client(\n",
    "    'sagemaker-runtime',\n",
    "    aws_access_key_id=AWS_ACCESS_KEY,\n",
    "    aws_secret_access_key=AWS_SECRET_KEY,\n",
    "    region_name=AWS_REGION_NAME\n",
    "\n",
    "    # aws_session_token=AWS_SESSION_TOKEN\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T06:44:16.424281Z",
     "start_time": "2024-08-05T06:44:16.373611Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "modelnumber = 1\n",
    "\n",
    "\n",
    "if modelnumber == 1:\n",
    "    endpoint_name = 'tensorflow-inference-2024-08-05-06-14-21-104'\n",
    "\n",
    "elif modelnumber == 2:\n",
    "\n",
    "    endpoint_name = 'tensorflow-inference-2024-08-05-06-24-06-679'\n",
    "\n",
    "elif modelnumber == 4:\n",
    "\n",
    "    endpoint_name = 'tensorflow-inference-2024-08-05-06-30-40-683'\n",
    "\n",
    "\n",
    "\n",
    "count=0\n",
    "LIMIT = 5\n",
    "directory = '../temp/'\n",
    "image_size = (224,224)\n",
    "\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    count=count+1\n",
    "    if count > LIMIT:\n",
    "        break\n",
    "    f = os.path.join(directory, filename)\n",
    "    # checking if it is a file\n",
    "    if os.path.isfile(f):\n",
    "\n",
    "        # Load the image\n",
    "        img = Image.open(f)\n",
    "        # Resize the image while maintaining the aspect ratio\n",
    "        img.thumbnail(image_size)\n",
    "        # Convert the image to a byte array\n",
    "        img_byte_array = np.expand_dims(img, 0)  # Create batch axis\n",
    "        body = json.dumps(img_byte_array.tolist())\n",
    "        content_type = 'application/json'\n",
    "        try:\n",
    "            ioc_response = client.invoke_endpoint(\n",
    "                EndpointName=endpoint_name,\n",
    "                Body=body,\n",
    "                ContentType=content_type,\n",
    "\n",
    "             )\n",
    "            response = json.loads(ioc_response['Body'].read())\n",
    "\n",
    "            if modelnumber == 1:\n",
    "                prediction_score_raw = list(response[\"predictions\"])[0][0]\n",
    "                prediction_score = prediction_score_raw\n",
    "\n",
    "                print(f\"{100 * prediction_score:.2f}% Terrain. Raw prediction score={prediction_score_raw}\")\n",
    "            elif modelnumber == 2:\n",
    "                prediction_score_raw = list(response[\"predictions\"])[0][0]\n",
    "                prediction_score =  prediction_score_raw\n",
    "\n",
    "                print(f\"{100 * prediction_score:.2f}% Avalanche.\")\n",
    "            elif modelnumber == 4:\n",
    "                print(response)\n",
    "                prediction_score_raw = list(response[\"predictions\"])[0]\n",
    "                glide = prediction_score_raw[0] * 100\n",
    "                loose = prediction_score_raw[1] * 100\n",
    "                slab = prediction_score_raw[2] * 100\n",
    "\n",
    "                ind = 0\n",
    "                max_element = prediction_score_raw[0]\n",
    "                for i in range (1,len(prediction_score_raw)): #iterate over array\n",
    "                    if prediction_score_raw[i] > max_element: #to check max value\n",
    "                        max_element = prediction_score_raw[i]\n",
    "                        ind = i\n",
    "\n",
    "                if ind == 0:\n",
    "                    avlType = 'Glide'\n",
    "                elif ind == 1:\n",
    "                    avlType = 'Loose'\n",
    "                elif ind == 2:\n",
    "                    avlType = 'Slab'\n",
    "                #prediction_score = 1/(1+np.exp(-prediction_score_raw) )\n",
    "\n",
    "                print(f\"Avalanche Type={avlType}, {100 * prediction_score_raw[ind]:.2f}%, All Values [Glide Loose Slab]={prediction_score_raw}%\")\n",
    "\n",
    "\n",
    "            # Plot the image\n",
    "            plt.figure(figsize=(6, 3))\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')  # Hide the axis\n",
    "            plt.show()\n",
    "        except Exception as error:\n",
    "            print(f\"error infering {error}\")\n",
    "        finally:\n",
    "            pass\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import boto3\n",
    "import botocore\n",
    "import urllib3\n",
    "print(\"boto3 version:\", boto3.__version__)\n",
    "print(\"botocore version:\", botocore.__version__)\n",
    "print(\"urllib3 version:\", urllib3.__version__)\n",
    "print(\"Pillow Image version: \",Image.__version__)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T04:05:55.857649Z",
     "start_time": "2024-08-05T04:05:55.853044Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
