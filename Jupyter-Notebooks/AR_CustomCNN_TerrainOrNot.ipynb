{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb3c8ef3-ffca-4641-b3a1-cd6d7f62a791",
   "metadata": {},
   "source": [
    "## Get data from bucket"
   ]
  },
  {
   "cell_type": "code",
   "id": "da81f724-75c1-40e9-a707-c0a18ce8182c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import os, sys\n",
    "from PIL import Image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "e1be0a1f-f19a-4efc-8fde-8ae665906a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your S3 bucket and the image key\n",
    "bucket_name = 's3-avalanche-guard'\n",
    "positive_image_key = 'data/experiments/exp01-terrain-binary/train/positive/2015-03-07 rosskogel-windegg (3).jpg'\n",
    "negative_image_key = 'data/experiments/exp01-terrain-binary/train/negative/ILSVRC2012_val_00000004_n04263257.JPEG'\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "f246cc9d-ceca-4021-bf92-0e1fc55d04b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a session using Amazon S3\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Get the image from S3\n",
    "response = s3.get_object(Bucket=bucket_name, Key=positive_image_key)\n",
    "image_data = response['Body'].read()\n",
    "\n",
    "# Open the image\n",
    "image = Image.open(BytesIO(image_data))\n",
    "\n",
    "# Plot the image\n",
    "plt.imshow(image)\n",
    "plt.axis('off')  # Hide the axis\n",
    "plt.show()\n",
    "\n",
    "# Negative Image\n",
    "# Get the image from S3\n",
    "response = s3.get_object(Bucket=bucket_name, Key=negative_image_key)\n",
    "image_data = response['Body'].read()\n",
    "\n",
    "# Open the image\n",
    "image = Image.open(BytesIO(image_data))\n",
    "\n",
    "# Plot the image\n",
    "plt.imshow(image)\n",
    "plt.axis('off')  # Hide the axis\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9a0a9b",
   "metadata": {},
   "source": [
    "## Train a Custom CNN model for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "id": "f55a8d59-3517-4720-9d07-65fe8dd1079c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tensorflow==2.11.0 "
   ]
  },
  {
   "cell_type": "code",
   "id": "00e8bf91-622e-47a6-a9ad-64a1d86790af",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pydot"
   ]
  },
  {
   "cell_type": "code",
   "id": "bcd2320f-001f-4548-982f-619e3b500a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q graphviz"
   ]
  },
  {
   "cell_type": "code",
   "id": "48bdedd2-4669-4d32-b6a5-9a7b93911944",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q --upgrade keras\n",
    "#!pip install -q --upgrade tensorflow\n",
    "\n",
    "#!pip install -q keras-nightly\n",
    "#!pip install -q tensorflow==2.12.0 --user\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "4d927b9b-b58b-4da8-aff9-3c8d73fae551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.applications import EfficientNetB4\n",
    "from tensorflow.keras.applications import EfficientNetV2B0\n",
    "from tensorflow.keras.applications.efficientnet_v2 import EfficientNetV2S\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras import utils as kutils\n",
    "#from keras import ops as kops\n",
    "\n",
    "import keras\n",
    "\n",
    "\n",
    "\n",
    "import boto3\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "id": "e9423fbf-a347-424b-81b4-3ada8aae3188",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)\n",
    "#print(layers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "id": "5510ed46-30f4-404a-a989-2364f46c341c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "id": "9733e937-ff75-4175-af46-5694a994532b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the S3 bucket paths\n",
    "# Set up the S3 bucket paths\n",
    "s3_bucket = 's3-avalanche-guard'\n",
    "s3_directory_key = 'data/experiments/exp01-terrain-binary/'\n",
    "\n",
    "#s3_train ='cropped_images_noaugm_TrainValTest_balanced/train'\n",
    "#s3_val = 'cropped_images_noaugm_TrainValTest_balanced/val'\n",
    "#s3_test = 'cropped_images_noaugm_TrainValTest_balanced/test'"
   ]
  },
  {
   "cell_type": "code",
   "id": "059212e3-f45b-4bff-9b9c-0a051949b9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local directory to save images\n",
    "local_directory = 'AR/images/local_image_directory'\n",
    "\n",
    "# Create the local directory if it doesn't exist\n",
    "if not os.path.exists(local_directory):\n",
    "    os.makedirs(local_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "e6fbb989-935b-432b-b8c8-01ebdb59929d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### DO NOT RUN\n",
    "RUN_THIS = False\n",
    "\n",
    "# Initialize a session using Amazon S3\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# List all objects in the S3 directory\n",
    "paginator = s3.get_paginator('list_objects_v2')\n",
    "pages = paginator.paginate(Bucket=bucket_name, Prefix=s3_directory_key)\n",
    "\n",
    "\n",
    "\n",
    "if RUN_THIS:\n",
    "    # Download each image and recreate the folder structure\n",
    "    for page in pages:\n",
    "        for obj in page['Contents']:\n",
    "            key = obj['Key']\n",
    "            if key.endswith('/'):  # Skip directories\n",
    "                continue\n",
    "            # Recreate the directory structure locally\n",
    "            relative_path = os.path.relpath(key, s3_directory_key)\n",
    "            local_file_path = os.path.join(local_directory, relative_path)\n",
    "            local_file_dir = os.path.dirname(local_file_path)\n",
    "            if not os.path.exists(local_file_dir):\n",
    "                os.makedirs(local_file_dir)\n",
    "            # Download the file\n",
    "            s3.download_file(bucket_name, key, local_file_path)\n",
    "\n",
    "            # resize\n",
    "            size = 224, 224\n",
    "            #outfile = os.path.splitext(local_file_path)[0] + \".jpg\"\n",
    "            im = Image.open(local_file_path)\n",
    "            im.thumbnail(size, Image.Resampling.LANCZOS)\n",
    "    #im.save(local_file_path, \"JPEG\")\n",
    "else:\n",
    "    print(\"Skipped downloading images from s3\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "cf5fc77c-6c97-4041-b714-1dbf200ef669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local Directory paths\n",
    "\n",
    "local_train = os.path.join(local_directory, 'train')\n",
    "local_val =  os.path.join(local_directory, 'val')\n",
    "local_test =  os.path.join(local_directory, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "id": "43f768fe-42fd-4a63-90a7-4af114e40f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load datasets\n",
    "def load_datasets(img_dir: [str], img_size=(224, 224), batch_size=32):\n",
    "\n",
    "    train_dataset = None\n",
    "    val_dataset = None\n",
    "    test_dataset = None\n",
    "\n",
    "    if len(img_dir) >= 1:\n",
    "        train_dir = img_dir[0]\n",
    "        print(f\"train dir:{train_dir}\")\n",
    "        train_dataset = image_dataset_from_directory(\n",
    "            train_dir,\n",
    "            labels='inferred',\n",
    "            class_names=['negative', 'positive'],\n",
    "            label_mode='int',\n",
    "            batch_size=batch_size,\n",
    "            image_size=img_size,\n",
    "            shuffle=True\n",
    "        )\n",
    "        val_dataset = None\n",
    "        test_dataset = None\n",
    "    \n",
    "    if len(img_dir) >= 2:\n",
    "        val_dir = img_dir[1]\n",
    "        print(f\"val dir:{val_dir}\")\n",
    "        val_dataset = image_dataset_from_directory(\n",
    "            val_dir,\n",
    "            labels='inferred',\n",
    "            class_names=['negative', 'positive'],\n",
    "            label_mode='int',\n",
    "            batch_size=batch_size,\n",
    "            image_size=img_size,\n",
    "            shuffle=False\n",
    "        )\n",
    "\n",
    "    if len(img_dir) >= 3:\n",
    "        test_dir = img_dir[2]\n",
    "        print(f\"test dir:{test_dir}\")\n",
    "        test_dataset = image_dataset_from_directory(\n",
    "            test_dir,\n",
    "            labels='inferred',\n",
    "            class_names=['negative', 'positive'],\n",
    "            label_mode='int',\n",
    "            batch_size=batch_size,\n",
    "            image_size=img_size,\n",
    "            shuffle=False\n",
    "        )\n",
    "\n",
    "        \n",
    "    return train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "id": "2c68732a-a47b-4d4e-b705-3ce4cf3e1bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train_dataset, val_dataset, test_dataset = load_datasets([local_train, local_val, local_test],(224, 224),32)"
   ]
  },
  {
   "cell_type": "code",
   "id": "c4532eaa-a11c-4524-8897-819d2cf8c5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "id": "48942846-a2b0-474f-a6aa-3a6199563614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cardinality\n",
    "# Cardinality is images/batch size\n",
    "print(f\"Number of training samples: {train_dataset.cardinality()}\")\n",
    "print(f\"Number of validation samples: {val_dataset.cardinality()}\")\n",
    "print(f\"Number of test samples: {test_dataset.cardinality()}\")\n",
    "print(train_dataset.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44a606a-eb75-40d6-82e3-98756a4e701a",
   "metadata": {},
   "source": [
    "#### Augment data\n",
    "\n",
    "some reference from https://keras.io/guides/transfer_learning/"
   ]
  },
  {
   "cell_type": "code",
   "id": "e68a08cd-417d-41af-bfbf-1cbee25dc7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation_layers = [\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "]\n",
    "\n",
    "\n",
    "def data_augmentation(x):\n",
    "    for layer in augmentation_layers:\n",
    "        x = layer(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "# aument only train dataset\n",
    "train_dataset_aug = train_dataset.map(lambda x, y: (data_augmentation(x), y))\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "52866c51-adac-4063-a335-27ddbfc0a3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize the augmented data\n",
    "print(train_dataset)\n",
    "for images, labels in train_dataset.take(1):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    first_image = images[0]\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        augmented_image = data_augmentation(np.expand_dims(first_image, 0))\n",
    "        plt.imshow(np.array(augmented_image[0]).astype(\"int32\"))\n",
    "        plt.title(int(labels[0]))\n",
    "        plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "c02a957d-f552-4308-b20d-2b48139cd252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build the model\n",
    "def xx_build_model(num_classes):\n",
    "    base_model = EfficientNetV2B0EfficientNetV2S(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = layers.Dropout(0.2)(x)  # Regularize with dropout\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    layerRange = []\n",
    "    for _layer in model.layers:\n",
    "        if _layer not in base_model.layers:\n",
    "            layerRange.append(_layer.name)\n",
    "            \n",
    "    trainable_layers = len(layerRange)\n",
    "    for idx,_layer in enumerate(layerRange):\n",
    "        if idx != 0 and idx != trainable_layers-1:\n",
    "            layerRange.remove(_layer)\n",
    "        \n",
    "    model.summary(show_trainable=True, layer_range=layerRange)    \n",
    "        \n",
    "        \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "id": "c2e301b9-ff12-4835-96ac-b0f35a05b752",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xx2_build_model(p_input_shape):\n",
    "    \n",
    "    base_model = keras.applications.Xception(\n",
    "        weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
    "        input_shape=p_input_shape,\n",
    "        include_top=False,\n",
    "    )  # Do not include the ImageNet classifier at the top.\n",
    "\n",
    "    # Freeze the base_model\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # Create new model on top\n",
    "    inputs = keras.Input(shape=(224, 224, 3))\n",
    "\n",
    "    # Pre-trained Xception weights requires that input be scaled\n",
    "    # from (0, 255) to a range of (-1., +1.), the rescaling layer\n",
    "    # outputs: `(inputs * scale) + offset`\n",
    "    scale_layer = keras.layers.Rescaling(scale=1 / 127.5, offset=-1)\n",
    "    x = scale_layer(inputs)\n",
    "\n",
    "    # The base model contains batchnorm layers. We want to keep them in inference mode\n",
    "    # when we unfreeze the base model for fine-tuning, so we make sure that the\n",
    "    # base_model is running in inference mode here.\n",
    "    x = base_model(x, training=False)\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n",
    "    outputs = keras.layers.Dense(1)(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    \n",
    "    # Print summary of only trainable \n",
    "    layerRange = []\n",
    "    for _layer in model.layers:\n",
    "        if layer.trainable:\n",
    "            layerRange.append(_layer.name)\n",
    "            \n",
    "    trainable_layers = len(layerRange)\n",
    "    for idx,_layer in enumerate(layerRange):\n",
    "        if idx != 0 and idx != trainable_layers-1:\n",
    "            layerRange.remove(_layer)\n",
    "        \n",
    "    model.summary(show_trainable=True, layer_range=layerRange)    \n",
    "\n",
    "    \n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be46a94d-22ab-4a54-9e90-5d3e7470f928",
   "metadata": {},
   "source": [
    "##### Build From Scratch \n",
    "(ref https://keras.io/examples/vision/image_classification_from_scratch/)"
   ]
  },
  {
   "cell_type": "code",
   "id": "697b1a07-6189-4c2e-9f47-d59707a1034a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, num_classes):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    # Entry block\n",
    "    x = layers.Rescaling(1.0 / 255)(inputs)\n",
    "    x = layers.Conv2D(128, 3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    for size in [256, 512, 728]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    if num_classes == 2:\n",
    "        units = 1\n",
    "    else:\n",
    "        units = num_classes\n",
    "\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    # We specify activation=None so as to return logits\n",
    "    outputs = layers.Dense(units, activation=None)(x)\n",
    "    \n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "fbff0cb6-3e3c-4cae-a777-4044a3282618",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset.class_names)\n",
    "y = set(np.concatenate([y for x, y in train_dataset_aug], axis=0))\n",
    "print(f\"y is {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "f154dd03-b506-4c52-989c-b88f9dd61760",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (224,224)\n",
    "model = build_model(input_shape=image_size + (3,), num_classes=2)\n",
    "model.summary(show_trainable=True, layer_range=None)    \n",
    "\n",
    "#keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "id": "7c665eb0-04de-4dc6-bd47-ff14e2a1cad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "####num_classes = len(train_dataset.class_names)\n",
    "####model = build_model(num_classes)\n",
    "\n",
    "# Compile the model\n",
    "####model.compile(optimizer=Adam(), \n",
    "####              loss='sparse_categorical_crossentropy', \n",
    "####              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "5053caea-5b34-491e-a5c7-00ce4f43da2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "'''\n",
    "_epochs = 5\n",
    "\n",
    "history = model.fit(train_dataset_aug, validation_data=val_dataset, epochs=_epochs)\n",
    "'''\n",
    "\n",
    "epochs = 25\n",
    "\n",
    "####callbacks = [\n",
    "####    keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.keras\"),\n",
    "####]\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(3e-4),\n",
    "    loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=[keras.metrics.BinaryAccuracy(name=\"acc\")],\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset_aug,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_dataset,\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "3a8116a1-85e0-4f9d-bf3a-a2e8c6a76dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "id": "dd70e3e1-669d-494f-ad64-b9334c77a65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "id": "ba28c27a-35f5-4846-8283-64e4d3528bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model_path = 'AR/models/Binary_TerrainOrNot_ARCNN_1'  # Local path to save the model\n",
    "model.save(local_model_path, save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "id": "7d03b3c2-40b0-42e2-a6b4-fc199de29b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    to_file='AR/models/Binary_TerrainOrNot_EfficientNetV2S_1.png',\n",
    "    show_shapes=False,\n",
    "    show_dtype=False,\n",
    "    show_layer_names=False,\n",
    "    rankdir='TB',\n",
    "    expand_nested=False,\n",
    "    dpi=200,\n",
    "    show_layer_activations=False,\n",
    "    show_trainable=False,\n",
    "    **kwargs\n",
    ")\n",
    "'''\n",
    "\n",
    "#tf.keras.utils.plot_model(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "cf4a5025-085b-487a-9e31-9724584de9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "acc = history.history['']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range()\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3ed0f1-6e34-4a3f-8dbf-e378fefd2d84",
   "metadata": {},
   "source": [
    "#### Run Inference from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "afeeae58-6dfb-4cd9-8f63-0e28e23f5046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 722 files belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 722 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# load test dataset \n",
    "\n",
    "test_dataset = image_dataset_from_directory(\n",
    "        local_test,\n",
    "        labels='inferred',\n",
    "        label_mode='int',\n",
    "        batch_size=32,\n",
    "        image_size=(224, 224),\n",
    "        shuffle=False\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "58bbfaba-1be1-48fc-aee7-378f49d751c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158/158 [==============================] - 272s 2s/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 39s 2s/step\n"
     ]
    }
   ],
   "source": [
    "output = model.predict(traintest_dataset) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "dfa11696-3f8a-4c56-8d81-d400ace888a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5043, 2)\n",
      "tf.Tensor(23, shape=(), dtype=int64)\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "print(output.shape)\n",
    "print(tf.data.experimental.cardinality(test_dataset))\n",
    "print(test_dataset.cardinality().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254ba61a-b0e0-437c-b41b-7674c1bcb76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "30b036cf-ada7-4b15-9e4c-7009296564c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TakeDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "print(np.array(train_dataset.take(42)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "b1839583-007f-491e-9bfa-205da1048f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_dataset.take(42):\n",
    "    #print(np.array(images))\n",
    "    #print(np.array(labels))\n",
    "    for i in range(32):\n",
    "        ax = plt.subplot(8, 4, i + 1)\n",
    "        \n",
    "        #neg_prob = float(output[i][0]) #round(float(output[i][0]),2)\n",
    "        #pos_prob = float(output[i][1]) #round(float(output[i][1]),2)\n",
    "\n",
    "        neg_prob = round(float(output[i][0]),2)\n",
    "        pos_prob = round(float(output[i][1]),2)\n",
    "        \n",
    "        if pos_prob > neg_prob:\n",
    "            pred_class = \"Terrain\"\n",
    "        else:\n",
    "            pred_class = \"Not-a-Terrain\"\n",
    "        \n",
    "        #print(labels[i],pos_prob)\n",
    "        print(f\"OLabel={labels[i]},PLabel={neg_prob},{pos_prob}\")\n",
    "        #plt.imshow(np.array(images[i]).astype(\"uint8\"))\n",
    "        #plt.title(f\"OLabel={labels[i]},PLabel={neg_prob},{pos_prob}\", fontsize = 6)\n",
    "        #plt.axis(\"off\")\n",
    "\n",
    "#print(train_dataset.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5fb0d8-2fb4-42a1-8e93-5316186c4bae",
   "metadata": {},
   "source": [
    "Motivation - https://keras.io/examples/vision/image_classification_from_scratch/"
   ]
  },
  {
   "cell_type": "code",
   "id": "5fa643cd-76a1-4b31-bf93-2839fd573d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import required module\n",
    "\n",
    "#print(directory) \n",
    "\n",
    "# iterate over files in\n",
    "# that directory\n",
    "i=0\n",
    "LIMIT = 70\n",
    "directory = local_test + \"/negative\"\n",
    "image_size = (224,224)\n",
    "\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    i=i+1\n",
    "    ##pred_class_arr = output[i-1]\n",
    "    ##if pred_class_arr[1] > pred_class_arr[0]:\n",
    "    ##    pred_class = \"Terrain\"\n",
    "    ##else:\n",
    "    ##    pred_class = \"Not-a-Terrain\"\n",
    "    ##print(f\"Index = {i} - Class = {pred_class}  -  ClassArray={pred_class_arr}\")\n",
    "    if i> LIMIT:\n",
    "        break\n",
    "    f = os.path.join(directory, filename)\n",
    "    # checking if it is a file\n",
    "    if os.path.isfile(f):\n",
    "        \n",
    "        img = kutils.load_img(f, target_size=image_size)\n",
    "        #plt.imshow(img)\n",
    "\n",
    "        img_array = kutils.img_to_array(img)\n",
    "        img_array = np.expand_dims(img_array, 0)  # Create batch axis\n",
    "\n",
    "        predictions = model.predict(img_array)\n",
    "        print(predictions) \n",
    "        #pred_neg = predictions[0][0]\n",
    "        #pred_pos = predictions[0][1]\n",
    "        prediction_score_raw = predictions[0,0]\n",
    "        prediction_score = 1/(1+np.exp(-prediction_score_raw) )\n",
    "        \n",
    "        \n",
    "        #pos_score = round(pred_pos, 5)\n",
    "        #print(f\"** Pred_neg_raw = {pred_neg} , Pred_pos_raw = {pred_pos} , Istoal 100%{pred_pos + pred_neg}. This image is {100 * (1 - pos_score):.2f}% Not-A-Terrain and {100 * pos_score:.2f}% Terrain.\")\n",
    "        print(f\"{100 * prediction_score:.2f}% Terrain.\")\n",
    "\n",
    "        # Open the image\n",
    "        ###image = mpimg.imread(f)\n",
    "        plt.figure(figsize=(6, 3))\n",
    "\n",
    "        # Plot the image\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')  # Hide the axis\n",
    "        plt.show()\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525db74c-ede7-4c72-ae78-6ee395289b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efa939c-f279-430e-8905-c61dff5fc68b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-1:742091327244:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
